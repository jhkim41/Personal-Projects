{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('/Users/jonghyunkim/repo/Tristan/chromedriver')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://sdgs.un.org/partnerships/browse'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_down_and_click(driver, element):\n",
    "    while True:\n",
    "        try:\n",
    "            element.click()\n",
    "            break\n",
    "        except:\n",
    "            driver.find_element(By.CSS_SELECTOR, 'body').send_keys(Keys.ARROW_DOWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_click(driver, element):\n",
    "    # Find all elements with the specified class\n",
    "\n",
    "\n",
    "    # Maximum wait time per element\n",
    "    max_wait_time = 10\n",
    "\n",
    "\n",
    "    end_time = time.time() + max_wait_time\n",
    "    while time.time() < end_time:\n",
    "        try:\n",
    "            # Try to move to the element and click it\n",
    "            WebDriverWait(driver, 2).until(EC.element_to_be_clickable(element))\n",
    "            element.click()\n",
    "            # print(f\"Element {element} is clickable and clicked\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            # print(f\"Element {element} not clickable yet: {e}\")\n",
    "            # Scroll down\n",
    "            # driver.execute_script(\"window.scrollBy(0, 100);\")\n",
    "            driver.find_element(By.CSS_SELECTOR, 'body').send_keys(Keys.ARROW_DOWN)\n",
    "            time.sleep(0.5)  # Adding a small delay to prevent overwhelming the browser\n",
    "\n",
    "    # # If the element is not found or clickable within the maximum wait time, continue to the next element\n",
    "    # if time.time() >= end_time:\n",
    "    #     raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_table = pd.read_excel('SDGS_on_process.xlsx', index_col=False)\n",
    "reference_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_exceptions=(NoSuchElementException,StaleElementReferenceException,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reference_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o = 1\n",
    "\n",
    "# while True:\n",
    "#     element = driver.find_elements(By.CLASS_NAME, 'page-item')[-2]\n",
    "#     gpt_click(driver, element)\n",
    "#     o += 1\n",
    "\n",
    "#     if o == 234:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing = driver.find_element(By.CLASS_NAME, 'offset-3').text.strip()\n",
    "total_number =int(processing.split()[-1])\n",
    "\n",
    "current_number = len(reference_table)\n",
    "\n",
    "if total_number > current_number:\n",
    "    diff = total_number - current_number\n",
    "else:\n",
    "    diff = 0\n",
    "\n",
    "current_list = list(reference_table['Case_Num'])\n",
    "new_list = []\n",
    "for nums in current_list:\n",
    "    new_list.append(nums+diff)\n",
    "\n",
    "not_founds_index = list(reference_table[reference_table['Case_Name'] == 'Page Not found']['Case_Num'])\n",
    "\n",
    "new_error_list = []\n",
    "for index in  not_founds_index:\n",
    "    new_error_list.append(index + diff)\n",
    "\n",
    "[4203, 4396, 7692]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_numbers = []\n",
    "cases_on_main_page = []\n",
    "case_names = []\n",
    "descrip_tab = []\n",
    "sdgs_tab = []\n",
    "deliver_tab = []\n",
    "resource_mobilized_tab = []\n",
    "progress_tab = []\n",
    "\n",
    "right_hand_info = []\n",
    "\n",
    "k = 1\n",
    "numbers = 1\n",
    "\n",
    "errors = []\n",
    "\n",
    "while True:\n",
    "\n",
    "    cases_in_page = driver.find_element(By.CLASS_NAME, 'view-content').find_elements(By.CLASS_NAME, 'views-row')\n",
    "\n",
    "    for case in cases_in_page:\n",
    "        # 가끔 클릭했는데 페이지가 안넘어가는 애들이 있어서 얘네는 따로 저장해주는 걸로.\n",
    "        if numbers in new_error_list:\n",
    "            errors.append((numbers, 'Page Not found'))\n",
    "            numbers += 1\n",
    "            continue\n",
    "\n",
    "        if numbers in new_list:\n",
    "            if reference_table['Description_Intro'][numbers-1-diff] != 'error':\n",
    "                numbers += 1\n",
    "                continue\n",
    "        \n",
    "        # if case.find_element(By.CLASS_NAME, 'views-field').text.strip() in list(ref['Case_Name']):\n",
    "        #     numbers += 1\n",
    "        #     continue\n",
    "            \n",
    "        try:\n",
    "            case2 = case.find_elements(By.CLASS_NAME, 'views-field')[0].find_element(By.CLASS_NAME, 'field-content')\n",
    "            cases_on_main_page.append(case2.text.strip())\n",
    "            gpt_click(driver, case2)\n",
    "            time.sleep(5)\n",
    "            # WebDriverWait(driver, 3,ignored_exceptions=ignored_exceptions).until(EC.presence_of_element_located((By.CLASS_NAME, 'separator')))\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            # 케이스의 이름 - identifier\n",
    "            case_name = soup.find(class_ = 'separator-bottom mt-5').text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                errors.append((numbers, case2.text.strip()))\n",
    "            except StaleElementReferenceException:\n",
    "                errors.append((numbers, 'Should trace based on numbers. Unknown Error'))\n",
    "            numbers += 1\n",
    "            continue\n",
    "        case_numbers.append(numbers)\n",
    "        case_names.append(case_name)\n",
    "\n",
    "\n",
    "\n",
    "        # Description Tab\n",
    "        description_tab = soup.find_all(class_ = 'details-wrapper')[0]\n",
    "        ## Intro 랑 Description만 필요\n",
    "        contents_names = description_tab.find_all(class_ = 'field__label')\n",
    "        contents_des = description_tab.find_all(class_ = 'field__item')\n",
    "        descripts = []\n",
    "\n",
    "        i = 0\n",
    "        while i < len(contents_names):\n",
    "            if contents_names[i].text.strip() in ['Intro', 'Description']:\n",
    "                descripts.append((contents_names[i].text.strip(), contents_des[i].text.strip()))\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "        descrip_tab.append(descripts)\n",
    "\n",
    "        #SDGS & Targets Tab\n",
    "        sdgs_targets_tab = soup.find_all(class_ = 'details-wrapper')[1]\n",
    "\n",
    "        GOALS = [sdgs_targets_tab.find_all(class_ = 'taxonomy-term container vocabulary-goals')[n].find(class_ = 'goal-title').text.strip() for n in range(len(sdgs_targets_tab.find_all(class_ = 'taxonomy-term container vocabulary-goals')))]\n",
    "        sdgs_tab.append(GOALS)\n",
    "\n",
    "\n",
    "\n",
    "        # Deliverables&Timeline tab\n",
    "        deliverable_tab = soup.find_all(class_ = 'details-wrapper')[3]\n",
    "        \n",
    "        \n",
    "        # time_line = deliverable_tab.find_all(class_ = 'datetime')\n",
    "        table_rows = deliverable_tab.find_all(class_ = 'paragraph paragraph--type--description-of-deliverable paragraph--view-mode--default')\n",
    "        i = 0\n",
    "        delivers = []\n",
    "        while i < len(table_rows):\n",
    "            time_line = table_rows[i].find(class_ = 'field field--name-field-date-of-deliverable field--type-datetime field--label-hidden field__item')\n",
    "            try:\n",
    "                time_line_text = time_line.text.strip() \n",
    "            except:\n",
    "                time_line_text = np.NaN\n",
    "            time_description = table_rows[i].find(class_ = 'clearfix text-formatted field field--name-field-description-of-deliverable field--type-text-long field--label-hidden field__item')\n",
    "            try:\n",
    "                time_description_text = time_description.text.strip()\n",
    "            except:\n",
    "                time_description_text = np.NaN\n",
    "\n",
    "            delivers.append((time_line_text, time_description_text))\n",
    "            i += 1\n",
    "        deliver_tab.append(delivers)\n",
    "\n",
    "\n",
    "        # Resources Mobilized\n",
    "        resources_tab = soup.find_all(class_ = 'details-wrapper')[4]\n",
    "        resource_table_rows  = resources_tab.find_all(class_ = 'paragraph paragraph--type--resources-devoted-to-delivery paragraph--view-mode--default')\n",
    "\n",
    "        i = 0\n",
    "        resources = [] \n",
    "        while i < len(resource_table_rows):\n",
    "            the_resource = resource_table_rows[i].find(class_ = 'field field--name-field-type field--type-list-string field--label-hidden field__item')\n",
    "            try:\n",
    "                the_resource_text = the_resource.text.strip()\n",
    "            except:\n",
    "                the_resource_text = np.NaN\n",
    "            \n",
    "            resource_description = resource_table_rows[i].find(class_ = 'field field--name-field-details field--type-string field--label-hidden field__item')\n",
    "            try:\n",
    "                resource_description_text = resource_description.text.strip()\n",
    "            except:\n",
    "                resource_description_text = np.NaN\n",
    "\n",
    "            resources.append((the_resource_text, resource_description_text))\n",
    "\n",
    "            i += 1\n",
    "        \n",
    "        resource_mobilized_tab.append(resources)\n",
    "\n",
    "\n",
    "        # Progress Reports\n",
    "        progress_report_tqb = soup.find_all(class_ = 'details-wrapper')[5]\n",
    "        progress_titles = progress_report_tqb.find_all(class_ = 'views-field views-field-title')\n",
    "        progress_status = progress_report_tqb.find_all(class_ = 'views-field views-field-field-progress-status')\n",
    "        progress_filing = progress_report_tqb.find_all(class_ = 'views-field views-field-created')\n",
    "\n",
    "        i = 1\n",
    "        progress_info = []\n",
    "        while i < len(progress_titles):\n",
    "            progress_info.append((progress_titles[i].text.strip(), progress_status[i].text.strip(), progress_filing[i].text.strip()))\n",
    "            i += 1\n",
    "\n",
    "        progress_tab.append(progress_info)\n",
    "\n",
    "\n",
    "        \n",
    "        ## Right_hand Side\n",
    "        right_side = soup.find(class_ = 'partnerships-basic-information-block container mt-5')\n",
    "        containers = right_side.find_all(class_ = 'views-element-container')\n",
    "        rights = []\n",
    "\n",
    "        for x in containers:\n",
    "            temp = []\n",
    "            if x.text.strip().split('\\n')[0] in ['Region', 'Geographical coverage', 'Countries', 'Entity', 'Timeline']:\n",
    "                pure = [h for h in x.text.strip().split('\\n') if (len(h) > 0) & (h != ' ')]\n",
    "                temp.append((pure[0], pure[1:]))\n",
    "            if len(temp) != 0:\n",
    "                rights.append(temp)\n",
    "\n",
    "        if len(rights) != 0:\n",
    "            right_hand_info.append(rights)\n",
    "        else:\n",
    "            right_hand_info.append(np.nan)\n",
    "\n",
    "        driver.back()\n",
    "        time.sleep(1.5)\n",
    "        # l += 1\n",
    "        numbers += 1\n",
    "    if numbers == total_number:\n",
    "        break    \n",
    "    # next_page_path = [x for x in driver.find_elements(By.CLASS_NAME, 'page-item') if x.text.strip() == str(k+1)][0]\n",
    "    # gpt_click(driver, next_page_path)\n",
    "    url = f'https://sdgs.un.org/partnerships/browse?page={k}'\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    k += 1\n",
    "\n",
    "\n",
    "\n",
    "# 우측에서 \n",
    "## Entity\n",
    "## Timeline 추가 (Start date, Completion date 가 있는데 completion date 가 없으면 없다고)\n",
    "## Completion 이 아닌 하나의 다른 종류의 date가 하나 있고, 그거가 관측되면 새로운 칼럼으로.\n",
    "\n",
    "\n",
    "#\n",
    "## Goal 의 dummy화\n",
    "## Country 도 더미화\n",
    "## 된거랑 아닌거랑.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_nums = []\n",
    "for x,y in errors:\n",
    "    error_nums.append(x)\n",
    "error_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(case_numbers))\n",
    "print(len(case_names))\n",
    "print(len(descrip_tab))\n",
    "print(len(sdgs_tab))\n",
    "print(len(deliver_tab))\n",
    "print(len(resource_mobilized_tab))\n",
    "print(len(progress_tab))\n",
    "\n",
    "print(len(right_hand_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_storage = []\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "for num in collection_num:\n",
    "    if num in error_nums:\n",
    "        case_num = errors[k][0]\n",
    "        case = errors[k][1]\n",
    "        description_intro = 'error'\n",
    "        description_des = 'error'\n",
    "        sdgs = 'error'\n",
    "        delivery_date = 'error'\n",
    "        delivery_des = 'error'\n",
    "        resource_name = 'error'\n",
    "        resource_des = 'error'\n",
    "        progress_t = 'error'\n",
    "        progress_s = 'error'\n",
    "        progress_f = 'error'\n",
    "        region = 'error'\n",
    "        geo_cover = 'error'\n",
    "        countries = 'error'\n",
    "        entity = 'error'\n",
    "        timeline = 'error'\n",
    "        k += 1\n",
    "    else:\n",
    "        case_num = case_numbers[j]\n",
    "        case = case_names[j]\n",
    "\n",
    "        if len(descrip_tab[j]) == 0:\n",
    "            description_intro = np.nan\n",
    "            description_des = np.nan\n",
    "        elif len(descrip_tab[j]) == 1:\n",
    "            if descrip_tab[j][0][0] == 'Intro':\n",
    "                description_intro = descrip_tab[j][0][1]\n",
    "                description_des = np.nan\n",
    "            elif descrip_tab[j][0][0] == 'Description':\n",
    "                description_intro = np.nan\n",
    "                description_des = descrip_tab[j][0][1]\n",
    "        else:\n",
    "            if descrip_tab[j][0][0] == 'Intro':\n",
    "                description_intro = descrip_tab[j][0][1]\n",
    "                description_des = descrip_tab[j][1][1]\n",
    "            elif descrip_tab[j][0][0] == 'Description':\n",
    "                description_intro = descrip_tab[j][1][1]\n",
    "                description_des = descrip_tab[j][0][1]\n",
    "\n",
    "        sdgs = sdgs_tab[j]\n",
    "\n",
    "        delivery_date = []\n",
    "        delivery_des = []\n",
    "\n",
    "        for x,y in deliver_tab[j]:\n",
    "            delivery_date.append(x)\n",
    "            delivery_des.append(y)\n",
    "\n",
    "        resource_name = []\n",
    "        resource_des = []\n",
    "\n",
    "        for x,y in resource_mobilized_tab[j]:\n",
    "            resource_name.append(x)\n",
    "            resource_des.append(y)\n",
    "\n",
    "        progress_t = []\n",
    "        progress_s = []\n",
    "        progress_f = []\n",
    "        \n",
    "        for x,y,z in progress_tab[j]:\n",
    "            progress_t.append(x)\n",
    "            progress_s.append(y)\n",
    "            progress_f.append(z)\n",
    "        \n",
    "\n",
    "        right_dict = {}\n",
    "\n",
    "        for element in right_hand_info[j]:\n",
    "            target = element[0]\n",
    "            right_dict[target[0]] = target[1]\n",
    "        \n",
    "        for word in ['Region', 'Geographical coverage', 'Countries']:\n",
    "            if word not in right_dict.keys():\n",
    "                right_dict[word] = np.NaN\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        region = right_dict['Region']\n",
    "        geo_cover = right_dict['Geographical coverage']\n",
    "        countries = right_dict['Countries']\n",
    "        entity = right_dict['Entity']\n",
    "        timeline = right_dict['Timeline']\n",
    "\n",
    "        \n",
    "\n",
    "        j += 1\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    # i += 1\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    series = pd.Series({'Case_Num':case_num, 'Case_Name' : case, 'Description_Intro' : description_intro, 'Description_Description' : description_des,\n",
    "               'SDGS&TARGETS' : sdgs, 'Delivery_Date' :  delivery_date, 'Delivery_Description' : delivery_des, 'Resource_Name': resource_name,\n",
    "               'Resource_Description': resource_des, 'Progress_Title': progress_t, 'Progress_Status': progress_s, 'Progress_Filing': progress_f,\n",
    "               'Region' : region, 'Geographical Coverage': geo_cover, 'Countries':countries, 'Entity':entity, 'Timeline':timeline})\n",
    "\n",
    "    series_storage.append(series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(series_storage)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.iloc[1,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < len(data):\n",
    "    j = 0\n",
    "    while j < len(data.columns):\n",
    "        if (type(data.iloc[i,j]) == list):\n",
    "            if len(data.iloc[i,j]) == 0:\n",
    "                data.iloc[i,j] = np.NaN\n",
    "        j += 1\n",
    "    i += 1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[4,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < len(data):\n",
    "    j = 0\n",
    "    while j < len(data.columns):\n",
    "        if data.iloc[i,j] == ['\\t\\t\\t\\t\\t\\t\\tN/A']:\n",
    "            data.iloc[i,j] = np.NaN\n",
    "        j += 1\n",
    "    i += 1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_table[reference_table['Case_Num'].isin(list(data['Case_Num'])) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_table2 = reference_table[reference_table['Case_Num'].isin(list(data['Case_Num'])) == False]\n",
    "reference_table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data) + len(reference_table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([reference_table2, data])\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data2.sort_values(by = 'Case_Num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.reset_index(inplace=True, drop=True)\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "while i < len(data3):\n",
    "    j = 0\n",
    "    while j < len(data3.columns):\n",
    "        if data3.iloc[i,j] == ['\\t\\t\\tN/A']:\n",
    "            data3.iloc[i,j] = np.NaN\n",
    "        j += 1\n",
    "    i += 1\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.to_excel('SDGS_on_process.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data =pd.read_excel('SDGS_on_process.xlsx', index_col=False)\n",
    "the_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "def convert_to_list(value):\n",
    "    if isinstance(value, str):\n",
    "        try:\n",
    "            # JSON 형식일 경우\n",
    "            return json.loads(value)\n",
    "        except json.JSONDecodeError:\n",
    "            try:\n",
    "                # 쉼표로 구분된 문자열일 경우\n",
    "                return ast.literal_eval(value)\n",
    "            except (ValueError, SyntaxError):\n",
    "                # 문자열 그대로 반환\n",
    "                return value\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_form = ['SDGS&TARGETS', 'Delivery_Date', 'Delivery_Description',\n",
    "       'Resource_Name', 'Resource_Description', 'Progress_Title',\n",
    "       'Progress_Status', 'Progress_Filing', 'Region', 'Geographical Coverage',\n",
    "       'Countries', 'Entity', 'Timeline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in list_form:\n",
    "    the_data[x] = the_data[x].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data['SDGS&TARGETS'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOAL1 = []\n",
    "GOAL2 = []\n",
    "GOAL3 = []\n",
    "GOAL4 = []\n",
    "GOAL5 = []\n",
    "GOAL6 = []\n",
    "GOAL7 = []\n",
    "GOAL8 = []\n",
    "GOAL9 = []\n",
    "GOAL10 = []\n",
    "GOAL11 = []\n",
    "GOAL12 = []\n",
    "GOAL13 = []\n",
    "GOAL14 = []\n",
    "GOAL15 = []\n",
    "GOAL16 = []\n",
    "GOAL17 = []\n",
    "\n",
    "Goal_dict = {'Goal 1' : GOAL1, 'Goal 2' : GOAL2, 'Goal 3': GOAL3,'Goal 4': GOAL4, 'Goal 5': GOAL5, 'Goal 6': GOAL6, 'Goal 7': GOAL7, 'Goal 8': GOAL8, 'Goal 9': GOAL9, 'Goal 10': GOAL10, 'Goal 11': GOAL11, 'Goal 12': GOAL12, 'Goal 13': GOAL13, 'Goal 14': GOAL14, 'Goal 15': GOAL15, 'Goal 16': GOAL16, 'Goal 17': GOAL17}\n",
    "\n",
    "\n",
    "for goals in list(the_data['SDGS&TARGETS']):\n",
    "    if type(goals) == float:\n",
    "        for key in list(Goal_dict.keys()):\n",
    "            Goal_dict[key].append(np.NaN)\n",
    "    elif goals == 'error':\n",
    "        for key in list(Goal_dict.keys()):\n",
    "            Goal_dict[key].append('error')\n",
    "    else:\n",
    "        for key in list(Goal_dict.keys()):\n",
    "\n",
    "            if key in goals:\n",
    "                Goal_dict[key].append(1)\n",
    "            else:\n",
    "                Goal_dict[key].append(0)\n",
    "goal_dummies = pd.DataFrame(Goal_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexa = 0\n",
    "odd = []\n",
    "nons = []\n",
    "for countries in list(the_data['Countries']):\n",
    "    if type(countries) == float:\n",
    "        nons.append(indexa)\n",
    "        indexa += 1\n",
    "        continue\n",
    "    if type(countries) != list:\n",
    "        odd.append(indexa)\n",
    "    indexa += 1\n",
    "len(odd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(the_data['Countries'])[4395]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data['Countries'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "countries_dict = {}\n",
    "number = 0\n",
    "\n",
    "for countries in list(the_data['Countries']):\n",
    "    # Handle NaN cases\n",
    "    if type(countries) == float:\n",
    "        for key in list(countries_dict.keys()):\n",
    "            countries_dict[key].append(np.NaN)\n",
    "        number += 1\n",
    "        continue\n",
    "    \n",
    "    # Handle 'error' cases\n",
    "    elif countries == 'error':\n",
    "        for key in list(countries_dict.keys()):\n",
    "            countries_dict[key].append('error')\n",
    "        number += 1\n",
    "        continue\n",
    "    \n",
    "    # Handle valid country lists\n",
    "    else:\n",
    "        for country in countries:\n",
    "            if country in countries_dict:\n",
    "                countries_dict[country].append(1)\n",
    "            else:\n",
    "                # Add new country with 0's for previous entries\n",
    "                countries_dict[country] = [0] * number\n",
    "                countries_dict[country].append(1)\n",
    "        \n",
    "        # Ensure all existing keys have the same length\n",
    "        for key in countries_dict.keys():\n",
    "            if len(countries_dict[key]) < number + 1:\n",
    "                countries_dict[key].append(0)\n",
    "    \n",
    "    number += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dummies = pd.DataFrame(countries_dict)\n",
    "country_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(country_dummies):\n",
    "    if i in nons:\n",
    "        j = 0\n",
    "        while j < len(country_dummies.columns):\n",
    "            country_dummies.iloc[i,j] == np.NaN\n",
    "            j += 1\n",
    "    \n",
    "    elif i in odd:\n",
    "        j = 0\n",
    "        while j < len(country_dummies.columns):\n",
    "            country_dummies.iloc[i,j] == 'error'\n",
    "            j += 1        \n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dummies.iloc[nons[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data2 = pd.concat([the_data, goal_dummies], axis = 1)\n",
    "the_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data3 = pd.concat([the_data2, country_dummies], axis = 1)\n",
    "the_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data3.to_excel('SDGS_with_dummies.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data.to_excel('SDGS_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
